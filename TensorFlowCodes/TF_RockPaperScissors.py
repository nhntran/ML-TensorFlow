
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-

### Learning TensorFlow with Laurence Moroney, Google Brain on Coursera
### /Users/trannguyen/TranData/WORK/BioinformaticsSpecialization_Tran_2019/\
###/MachineLearning/TensorFlow/TensorFlowCodes

#The dataset has 2,892 images of hands in rock, paper, scissors poses
# with white background.

#Download the data
# !wget --no-check-certificate \
#    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip \
#    -O data/rock-paper-scissors-data/rps.zip
  
# !wget --no-check-certificate \
#    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip \
#    -O data/rock-paper-scissors-data/rps-test-set.zip

#Download the prediction data
#https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-validation.zip

import os
import numpy as np
import h5py
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import tensorflow as tf
import keras_preprocessing
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator


class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('acc')>0.99):
            print("\nReached 99% accuracy so cancelling training!")
            self.model.stop_training=True


def check_display_data(local_path1):
    
    ### checking the data
    train_rock_dir = os.path.join(local_path1 + 'train/rock')
    train_rock_names = os.listdir(train_rock_dir)
    train_paper_dir = os.path.join(local_path1 + 'train/paper')
    train_paper_names = os.listdir(train_paper_dir)
    train_scissors_dir = os.path.join(local_path1 + 'train/scissors')
    train_scissors_names = os.listdir(train_scissors_dir)

    print('Total training rock images:',len(train_rock_names))
    print('Total training paper images:', len(train_paper_names))
    print('Total training scissors images:', len(train_scissors_names))
    ### display the data
    #need matplotlib

    pic_index = 2
    next_rock_pic = [os.path.join(train_rock_dir,fname)
                        for fname in train_rock_names[pic_index-2:pic_index]]
    next_paper_pic = [os.path.join(train_paper_dir,fname)
                        for fname in train_paper_names[pic_index-2:pic_index]]
    next_scissors_pic = [os.path.join(train_scissors_dir,fname)
                        for fname in train_scissors_names[pic_index-2:pic_index]]                    

    for i, img_path in enumerate(next_rock_pic + next_paper_pic
                        + next_scissors_pic):
        img = mpimg.imread(img_path)
        plt.imshow(img)
        plt.show()

def generating_data(local_path1):
    train_datagen = ImageDataGenerator(rescale = 1/255,
                                        rotation_range = 40,
                                        width_shift_range = 0.2,
                                        height_shift_range = 0.2,
                                        shear_range = 0.2,
                                        zoom_range = 0.2,
                                        horizontal_flip = True,
                                        fill_mode = 'nearest')
                    #fill empty pixel generated by transformation  

    validation_datagen = ImageDataGenerator(rescale = 1/255)

    train_gen = train_datagen.flow_from_directory(
        local_path1 + 'train/',
        target_size = (150,150),
        class_mode = 'categorical'
        )

    validation_gen = validation_datagen.flow_from_directory(
        local_path1 + 'validation/',
        target_size = (150,150),
        class_mode = 'categorical'
        )

    return train_gen, validation_gen

def building_model(local_path1):
    callbacks = myCallback()

    model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
    ])

    model.summary()
    model.compile(optimizer = 'rmsprop',
                    loss = 'categorical_crossentropy',
                    metrics = ['acc'])
    
    train_generator, validation_generator=generating_data(local_path1)

    history = model.fit_generator(
        train_generator,
        epochs = 25, verbose = 2,
        validation_data = validation_generator,
        callbacks = [callbacks]
        )
    #verbose=2: Note the values per epoch (loss, accuracy, 
    #validation loss, validation accuracy)
    ## retrieve values
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    #evaluate the model
    model_evaluation(acc, val_acc, loss, val_loss)
    ## save model
    model.save('TF_rock_paper_scissors.h5') #after training, saving the model into the .h5 file

    return model

def model_evaluation(acc, val_acc, loss, val_loss):
    epochs = range(len(acc)) #get number of epochs

    #plot training and validation accuracy and loss
    plt.plot(epochs,acc, 'r', "Training Accuracy")
    plt.plot(epochs,val_acc, 'b')
    plt.title("Training and validation accuracy")

    plt.plot(epochs,loss)
    plt.plot(epochs,val_loss)
    plt.title("Training and validation loss")

def prediction_rock_paper_scissors(local_path2, model):
    prediction_dir = os.path.join(local_path2)
    prediction_names = os.listdir(prediction_dir)

    for fn in prediction_names:
     
      img = image.load_img(local_path2+fn, target_size=(150, 150))
      x = image.img_to_array(img)
      x = np.expand_dims(x, axis=0)

      images = np.vstack([x])
      classes = model.predict(images, batch_size=10)
      print(fn)
      print(classes)


########################################################################
# The main() function
def main():
    
    #print(tf.__version__)
    local_path1 = 'data/rock-paper-scissors-data/'
    local_path2 = 'data/rock-paper-scissors-data/prediction/'

    # First time running: training model
    check_display_data(local_path1)
    model = building_model(local_path1)
    prediction_rock_paper_scissors(local_path2, model)

    # Second time running: Loading the model again
    # new_model = tf.keras.models.load_model('TF_Dogs_Cats_TransferLearning0.h5')
    # prediction_cat_dog(local_path2, new_model)

#######################################################################
# Standard boilerplate to call the main() function to begin
# the program.
if __name__ == '__main__':
  main()

